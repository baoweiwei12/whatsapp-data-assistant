from datetime import datetime
import logging
from typing import List
import httpx
from openai import OpenAI
import json
from pydantic import BaseModel
import config
from app.sql import crud
from app.sql.database import SessionLocal
import csv
import io
import base64
from app.whatsapp_api.chat import send_file
from app.logger import logger

if config.HTTP_PROXY is not None:
    # Clash ä»£ç†åœ°å€
    custom_http_client = httpx.Client(timeout=100.0, proxies=config.HTTP_PROXY)
else:
    custom_http_client = None
client = OpenAI(api_key=config.OPENAI_API_KEY, base_url=config.OPENAI_BASE_URL,http_client=custom_http_client,max_retries=2)


class GoodsData(BaseModel):
    csv_data: str | None
    csv_base64_data: bytes | None


class FuncGoodsInfoResponse(BaseModel):
    is_matched_info: bool
    goods_data: GoodsData
    message: str | None


def get_goods_info_from_db_to_csv(
    limit: int = 500,
    start_timestamp: str | None = None,
    end_timestamp: str | None = None,
    key_words: str | None = None,
    sender_phone_number: str | None = None,
    sender_display_name: str | None = None,
):
    try:
        logger.info(
            f"æ­£åœ¨æŸ¥è¯¢èŠå¤©è®°å½• - {limit} - {start_timestamp} - {end_timestamp} - {key_words} - {sender_phone_number} - {sender_display_name}"
        )
        db = SessionLocal()
        goods_infomation = crud.get_goods_information(
            db,
            limit,
            start_timestamp,
            end_timestamp,
            key_words,
            sender_phone_number,
            sender_display_name,
        )
        if len(goods_infomation) == 0:
            return FuncGoodsInfoResponse(
                is_matched_info=False,
                goods_data=GoodsData(csv_data=None, csv_base64_data=None),
                message="æ²¡æœ‰æŸ¥è¯¢åˆ°ä»»ä½•ä¿¡æ¯",
            )
        # ä½¿ç”¨å†…å­˜ä¸­çš„ç¼“å†²åŒºæ¥æ„å»ºCSVæ ¼å¼çš„æ•°æ®
        output = io.StringIO()
        writer = csv.writer(output)

        # å†™å…¥åˆ—å
        writer.writerow(
            [
                "å•†å“ä¿¡æ¯å‘å¸ƒæ—¶é—´",
                "å‘å¸ƒè€…æ‰‹æœºå·",
                "å‘å¸ƒè€…æ˜µç§°",
                "å•†å“è¯¦æƒ…",
                "ä»·æ ¼",
            ]
        )

        # å†™å…¥æ¯æ¡ç¾¤ç»„æ¶ˆæ¯çš„æ•°æ®
        for good_info in goods_infomation:
            writer.writerow(
                [
                    good_info.message.timestamp,
                    good_info.message.sender_phone_number,
                    good_info.message.sender_display_name,
                    good_info.detail,
                    good_info.price,
                ]
            )

        # è·å–CSVæ ¼å¼çš„å­—ç¬¦ä¸²å¹¶è¿”å›
        output.seek(0)
        csv_data = output.getvalue()
        base64_csv_data = base64.b64encode(csv_data.encode("utf-8"))
        logger.info(f"æŸ¥è¯¢æˆåŠŸ")
        return FuncGoodsInfoResponse(
            is_matched_info=True,
            goods_data=GoodsData(csv_data=csv_data, csv_base64_data=base64_csv_data),
            message=None,
        )
    except Exception as e:
        logger.error(f"å‡½æ•°è¿è¡Œå¤±è´¥:{e}")
        return FuncGoodsInfoResponse(
            is_matched_info=False,
            goods_data=GoodsData(csv_data=None, csv_base64_data=None),
            message=f"å‡½æ•°è¿è¡Œå¤±è´¥:{e}",
        )
    finally:
        db.close()


tools = [
    {
        "type": "function",
        "function": {
            "name": "get_goods_info_from_db_to_csv",
            "description": "Retrieve group messages based on specified filters such as date range, content, sender's phone number, and sender's display name",
            "parameters": {
                "type": "object",
                "properties": {
                    "limit": {
                        "type": "integer",
                        "description": "The maximum number of goods information (default is 500)",
                    },
                    "start_timestamp": {
                        "type": "string",
                        "format": "date-time",
                        "description": "The start timestamp in the format %Y-%m-%d %H:%M:%S for goods information",
                    },
                    "end_timestamp": {
                        "type": "string",
                        "format": "date-time",
                        "description": "The end timestamp in the format %Y-%m-%d %H:%M:%S for goods information",
                    },
                    "key_words": {
                        "type": "string",
                        "description": "The keywords to search within goods information detail",
                    },
                    "sender_phone_number": {
                        "type": "string",
                        "description": "The phone number of the goods information sender for filtering information",
                    },
                    "sender_display_name": {
                        "type": "string",
                        "description": "The display name of the goods information sender for filtering information",
                    },
                },
            },
            "required": [],
        },
    }
]

available_functions = {
    "get_goods_info_from_db_to_csv": get_goods_info_from_db_to_csv,
}

system_prompt = f"ç°åœ¨çš„æ—¶é—´æ˜¯{datetime.now().strftime('%Y-%m-%d %H:%M:%S')},ä½ æ˜¯ChatGPTæ‰‹è¡¨å•†å“æŸ¥è¯¢åŠ©æ‰‹ï¼Œä½ éœ€è¦åœ¨æ•°æ®åº“ä¸­æ£€ç´¢å•†å“æ•°æ®ï¼Œè¿™äº›å•†å“æ•°æ®éƒ½æ˜¯å…³äºæ‰‹è¡¨çš„ï¼Œå‡½æ•°ä¼šä¸ºä½ è¿”å›CSVæ ¼å¼çš„æ‰‹è¡¨å•†å“ä¿¡æ¯ï¼Œä½ éœ€è¦æ ¹æ®è¿™äº›æ‰‹è¡¨å•†å“ä¿¡æ¯å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œå›ç­”æ—¶éœ€è¦é™„å¸¦å•†å“ä¿¡æ¯å‘å¸ƒæ—¶é—´,å‘å¸ƒè€…æ‰‹æœºå·,å‘å¸ƒè€…æ˜µç§°,å•†å“è¯¦æƒ…,ä»·æ ¼,ä»¥æ¸…æ™°çš„æ–¹å¼å‘ˆç°,å•†å“è¯¦æƒ…è¯·åŸæ ·å±•ç¤ºï¼Œä¸è¦çœç•¥ä»»ä½•ã€‚"

from openai.types.chat import ChatCompletion


class RunConResponese(BaseModel):
    func_data: str | None
    chat_completion: ChatCompletion


def run_conversation(messages: list):
    """
    è¿è¡Œå¯¹è¯æµç¨‹ã€‚
    
    å‚æ•°:
    - messages: ä¸€ä¸ªåŒ…å«å¯¹è¯å†…å®¹çš„åˆ—è¡¨ï¼Œæ¯æ¡å¯¹è¯ä½œä¸ºä¸€ä¸ªå­—å…¸ï¼Œå­—å…¸åŒ…å«"role"å’Œ"content"é”®å€¼å¯¹ã€‚
    
    è¿”å›å€¼:
    - RunConResponeseå¯¹è±¡ï¼ŒåŒ…å«å‡½æ•°å“åº”æ•°æ®å’ŒèŠå¤©å®Œæˆä¿¡æ¯ã€‚
    """
    
    # åˆå§‹åŒ–OpenAIæ¨¡å‹
    model = config.OPENAI_MODEL
    # ä¸ºå¯¹è¯æ·»åŠ ç³»ç»Ÿæç¤º
    messages = [{"role": "system", "content": system_prompt}] + messages
    # å‘OpenAIå‘é€èŠå¤©è¯·æ±‚å¹¶è·å–å“åº”
    response = client.chat.completions.create(
        model=model,
        messages=messages,
        tools=tools,  # type: ignore
        tool_choice="auto",
    )
    # è§£æå“åº”æ¶ˆæ¯
    response_message = response.choices[0].message
    tool_calls = response_message.tool_calls

    if tool_calls:
        # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œå°†å“åº”æ¶ˆæ¯æ·»åŠ åˆ°å¯¹è¯ä¸­
        messages.append(response_message)

        # éå†å¹¶å¤„ç†æ¯ä¸ªå·¥å…·è°ƒç”¨
        for tool_call in tool_calls:
            function_name = tool_call.function.name
            function_to_call = available_functions[function_name]
            function_args = json.loads(tool_call.function.arguments)
            # è°ƒç”¨ç›¸åº”çš„å‡½æ•°ï¼Œå¹¶å¤„ç†è¿”å›çš„ç»“æœ
            function_response = function_to_call(**function_args)
            if function_response.is_matched_info:
                # å¦‚æœè¿”å›ä¿¡æ¯åŒ¹é…ï¼Œæ·»åŠ å•†å“æ•°æ®åˆ°å¯¹è¯ä¸­
                messages.append(
                    {
                        "tool_call_id": tool_call.id,
                        "role": "tool",
                        "name": function_name,
                        "content": function_response.goods_data.csv_data,
                    }
                )
            else:
                # å¦åˆ™ï¼Œæ·»åŠ é”™è¯¯ä¿¡æ¯åˆ°å¯¹è¯ä¸­
                messages.append(
                    {
                        "tool_call_id": tool_call.id,
                        "role": "tool",
                        "name": function_name,
                        "content": function_response.message,
                    }
                )
        # å‘é€åŒ…å«å·¥å…·è°ƒç”¨ç»“æœçš„å¯¹è¯è¯·æ±‚ï¼Œå¹¶è·å–äºŒæ¬¡å“åº”
        second_response = client.chat.completions.create(
            model=model,
            messages=messages,
        )
        # è¿”å›å‡½æ•°æ•°æ®å’ŒäºŒæ¬¡èŠå¤©å“åº”
        return RunConResponese(
            func_data=function_response.goods_data.csv_data,
            chat_completion=second_response,
        )
    else:
        # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›åŸå§‹å“åº”
        return RunConResponese(func_data=None, chat_completion=response)


class AnalyzeDataError(Exception):
    pass


class Info(BaseModel):
    detail: str
    price: int | None


class GoodsInfo(BaseModel):
    is_include_commodity_information: bool
    information: List[Info]


def analyze_text(text: str):
    model = "gpt-3.5-turbo-0125"
    system_prompt = """
    ä½œä¸ºä¸€ä¸ªåŠ©æ‰‹ï¼Œä½ çš„ä»»åŠ¡æ˜¯ä»æ¶ˆæ¯ä¸­æå–å•†å“ä¿¡æ¯ã€‚å¦‚æœæ¶ˆæ¯ä¸­ä¸åŒ…å«å•†å“ä¿¡æ¯ï¼Œè¯·å°† "is_include_commodity_information" è®¾ç½®ä¸º falseï¼Œå¹¶ç¡®ä¿ "information" å±æ€§ä¸ºç©ºæ•°ç»„ã€‚å¦‚æœæ¶ˆæ¯ä¸­åŒ…å«å•†å“ä¿¡æ¯ï¼Œè¯·æå–æ‰€æœ‰å•†å“ä¿¡æ¯å¹¶æ”¾å…¥ "information" æ•°ç»„ä¸­ã€‚åŠ¡å¿…ç­›é€‰å‡ºæ‰€æœ‰å¯èƒ½çš„å•†å“ä¿¡æ¯ï¼Œå¹¶å°½å¯èƒ½å¤šåœ°æå–å•†å“ä¿¡æ¯,æœ‰äº›å•†å“å¯èƒ½åªæœ‰æŠ˜æ‰£æ²¡æœ‰ä»·æ ¼ï¼Œä½ ä¹Ÿéœ€è¦æå–å‡ºæ¥ï¼Œè®¾ç½®priceä¸ºnullå³å¯ã€‚ä»¥ä¸‹æ˜¯éœ€è¦è¿”å›çš„ JSON æ¶ˆæ¯ç¤ºä¾‹ã€‚æ³¨æ„ï¼šä¸è¦æ¼æ‰ä»»ä½•ä¸€æ¡å¯èƒ½çš„å•†å“ä¿¡æ¯ã€‚

    <jsonæ¶ˆæ¯ç¤ºä¾‹>
    {
        "is_include_commodity_information": true,
        "information": [
            {
                "detail": "4962/200R $208000 1/2024",
                "price":208000
            },
            {
                "detail": "126720vtnr jub n2ğŸ·$141000",
                "price": 141000
            },
            {
                "detail": "5100-1140-52A - 38%",
                "price": null
            },
            {
                "detail": "42410402001003 - 38%",
                "price": null
            },
            {
                "detail": "311.92.44.30.01.001 $84,600 -8%",
                "price": 84600
            },
            {
                "detail": "116244 Rhodium Floral Motif Both Tag Warranty Card 2014 $77,800",
                "price": 77800
            }
        ]
    }
    </jsonæ¶ˆæ¯ç¤ºä¾‹>
    """

    response = client.chat.completions.create(
        model=model,
        response_format={"type": "json_object"},
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": text},
        ],
        temperature=0,
        max_tokens=4096,
    )
    json_message = response.choices[0].message.content
    if json_message is None:
        raise AnalyzeDataError("json_messageä¸ºç©º")
    message_dict = json.loads(json_message)

    return GoodsInfo(**message_dict)

